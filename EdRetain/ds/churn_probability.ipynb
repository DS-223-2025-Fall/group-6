{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bf3aa14-19c1-4894-b407-3ace9cda512d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported successfully\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from sqlalchemy import text\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from Database.database import engine, SessionLocal\n",
    "from sqlalchemy.orm import Session\n",
    "from Database.models import FactUserAnalyticsSnapshot, FactUserDailyActivity, ModelPerformanceMetrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Display Configuration\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "print(\"Imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dfbc1c7-9df1-4c46-8cf8-ad503e530a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LOADING RFM + ACTIVITY DATA FROM DATABASE\n",
      "================================================================================\n",
      "Loading RFM data...\n",
      "Loaded 802 RFM records\n",
      "Loading activity data from fact_user_daily_activity...\n",
      "Activity DataFrame columns: ['user_key', 'date_key', 'subscription_plan_key', 'campaign_key', 'logins_count', 'sessions_count', 'minutes_watched', 'lessons_completed', 'quizzes_attempted', 'distinct_courses_accessed', 'active_days_last_30d', 'days_since_last_login', 'is_inactive_7d_flag', 'active_courses_count', 'completed_courses_total']\n",
      "Activity DataFrame shape: (49565, 15)\n",
      "   user_key  date_key  subscription_plan_key  campaign_key  logins_count  sessions_count  minutes_watched  lessons_completed  quizzes_attempted  distinct_courses_accessed  active_days_last_30d  days_since_last_login  is_inactive_7d_flag  active_courses_count  completed_courses_total\n",
      "0       788  20250830                      1            18             2               2              121                  3                  5                          3                    19                      1                False                     3                        3\n",
      "1       921  20250830                      3            21             5               4               49                  6                  2                          3                    29                      2                False                     3                        6\n",
      "2       292  20250830                      4            27             0               0                0                  0                  0                          0                     1                     58                 True                     0                        0\n",
      "3       456  20250830                      1            39             0               0                0                  0                  0                          0                    12                     23                 True                     0                        0\n",
      "4       803  20250830                      5            49             3               1              198                  1                  5                          2                    21                      4                False                     2                        1\n",
      "Aggregating activity metrics...\n",
      "Detecting subscription changes...\n",
      "Detected downgrades:\n",
      "  Users with downgrades: 808\n",
      "  Users without downgrades: 192\n",
      "Merging datasets...\n",
      "Loaded 802 premium users with activity data\n",
      "\n",
      "Churn Distribution:\n",
      "  Retained (0):  484 (60.3%)\n",
      "  Churned (1):   318 (39.7%)\n",
      "\n",
      "Churn Breakdown by Reason:\n",
      "  Inactive (>30 days):          155\n",
      "  In churned segments:          184\n",
      "  Downgraded subscription:      610\n",
      "  Very low engagement:          0\n",
      "  Total churned (with overlap): 318\n",
      "\n",
      "Activity Statistics:\n",
      "  Avg logins (90d):             104.0\n",
      "  Avg minutes watched (90d):    5366.0\n",
      "  Avg lessons completed (90d):  175.1\n",
      "  Avg active courses:           3.0\n",
      "\n",
      "Churn target variable created with activity features\n"
     ]
    }
   ],
   "source": [
    "#Loading RFM + Activity data using ORM\n",
    "\n",
    "snapshot_date_key = int(datetime.now().strftime(\"%Y%m%d\"))\n",
    "start_date = datetime.now() - timedelta(days=90)\n",
    "start_date_key = int(start_date.strftime(\"%Y%m%d\"))\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"LOADING RFM + ACTIVITY DATA FROM DATABASE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "#Including users with subscriptions only\n",
    "print(\"Loading RFM data...\")\n",
    "with SessionLocal() as session:\n",
    "    rfm_records = session.query(FactUserAnalyticsSnapshot).filter(\n",
    "        FactUserAnalyticsSnapshot.snapshot_date_key == snapshot_date_key,\n",
    "        FactUserAnalyticsSnapshot.subscription_plan_key.in_([2, 3, 4, 5])\n",
    "    ).all()\n",
    "    \n",
    "    rfm_data = [{\n",
    "        'user_key': r.user_key,\n",
    "        'snapshot_date_key': r.snapshot_date_key,\n",
    "        'subscription_plan_key': r.subscription_plan_key,\n",
    "        'rfm_recency': r.rfm_recency,\n",
    "        'rfm_frequency': r.rfm_frequency,\n",
    "        'rfm_monetary': r.rfm_monetary,\n",
    "        'rfm_r_score': r.rfm_r_score,\n",
    "        'rfm_f_score': r.rfm_f_score,\n",
    "        'rfm_m_score': r.rfm_m_score,\n",
    "        'rfm_segment': r.rfm_segment,\n",
    "        'segment_label': r.segment_label,\n",
    "        'engagement_level': r.engagement_level\n",
    "    } for r in rfm_records]\n",
    "\n",
    "rfm_df = pd.DataFrame(rfm_data)\n",
    "print(f\"Loaded {len(rfm_df):,} RFM records\")\n",
    "\n",
    "print(\"Loading activity data from fact_user_daily_activity...\")\n",
    "\n",
    "with SessionLocal() as session:\n",
    "    activity_records = session.query(FactUserDailyActivity).all()\n",
    "    activity_data = [{\n",
    "        'user_key': r.user_key,\n",
    "        'date_key': r.date_key,\n",
    "        'subscription_plan_key': r.subscription_plan_key,\n",
    "        'campaign_key': r.campaign_key,\n",
    "        'logins_count': r.logins_count,\n",
    "        'sessions_count': r.sessions_count,\n",
    "        'minutes_watched': r.minutes_watched,\n",
    "        'lessons_completed': r.lessons_completed,\n",
    "        'quizzes_attempted': r.quizzes_attempted,\n",
    "        'distinct_courses_accessed': r.distinct_courses_accessed,\n",
    "        'active_days_last_30d': r.active_days_last_30d,\n",
    "        'days_since_last_login': r.days_since_last_login,\n",
    "        'is_inactive_7d_flag': r.is_inactive_7d_flag,\n",
    "        'active_courses_count': r.active_courses_count,\n",
    "        'completed_courses_total': r.completed_courses_total,\n",
    "    } for r in activity_records]\n",
    "\n",
    "activity_df = pd.DataFrame(activity_data)\n",
    "\n",
    "print(\"Activity DataFrame columns:\", activity_df.columns.tolist())\n",
    "print(\"Activity DataFrame shape:\", activity_df.shape)\n",
    "print(activity_df.head())\n",
    "\n",
    "print(\"Aggregating activity metrics...\")\n",
    "activity_agg = activity_df.groupby('user_key').agg({\n",
    "    'logins_count': 'sum',\n",
    "    'sessions_count': 'sum',\n",
    "    'minutes_watched': 'sum',\n",
    "    'lessons_completed': 'sum',\n",
    "    'quizzes_attempted': 'sum',\n",
    "    'distinct_courses_accessed': 'max',\n",
    "    'active_days_last_30d': 'mean',\n",
    "    'days_since_last_login': 'min',\n",
    "    'is_inactive_7d_flag': 'sum',\n",
    "    'active_courses_count': 'max',\n",
    "    'completed_courses_total': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "activity_agg.columns = [\n",
    "    'user_key',\n",
    "    'logins_90d',\n",
    "    'sessions_90d',\n",
    "    'minutes_watched_90d',\n",
    "    'lessons_completed_90d',\n",
    "    'quizzes_attempted_90d',\n",
    "    'courses_accessed',\n",
    "    'avg_active_days_30d',\n",
    "    'days_since_last_login',\n",
    "    'inactive_7d_count',\n",
    "    'active_courses',\n",
    "    'completed_courses'\n",
    "]\n",
    "\n",
    "print(\"Detecting subscription changes...\")\n",
    "\n",
    "user_subscription_changes = activity_df.groupby('user_key').agg({\n",
    "    'subscription_plan_key': ['first', 'last', 'min', 'max'],\n",
    "    'date_key': ['min', 'max']\n",
    "}).reset_index()\n",
    "\n",
    "user_subscription_changes.columns = [\n",
    "    'user_key', \n",
    "    'first_plan', 'last_plan', \n",
    "    'min_plan', 'max_plan',\n",
    "    'first_date', 'last_date'\n",
    "]\n",
    "\n",
    "user_subscription_changes['has_downgraded'] = (\n",
    "    user_subscription_changes['last_plan'] < user_subscription_changes['max_plan']\n",
    ").astype(int)\n",
    "\n",
    "downgrade_df = user_subscription_changes[['user_key', 'has_downgraded']]\n",
    "\n",
    "print(f\"Detected downgrades:\")\n",
    "print(f\"  Users with downgrades: {(downgrade_df['has_downgraded'] == 1).sum():,}\")\n",
    "print(f\"  Users without downgrades: {(downgrade_df['has_downgraded'] == 0).sum():,}\")\n",
    "\n",
    "print(\"Merging datasets...\")\n",
    "df = rfm_df.merge(activity_agg, on='user_key', how='left')\n",
    "df = df.merge(downgrade_df, on='user_key', how='left')\n",
    "\n",
    "df['logins_90d'] = df['logins_90d'].fillna(0)\n",
    "df['sessions_90d'] = df['sessions_90d'].fillna(0)\n",
    "df['minutes_watched_90d'] = df['minutes_watched_90d'].fillna(0)\n",
    "df['lessons_completed_90d'] = df['lessons_completed_90d'].fillna(0)\n",
    "df['quizzes_attempted_90d'] = df['quizzes_attempted_90d'].fillna(0)\n",
    "df['courses_accessed'] = df['courses_accessed'].fillna(0)\n",
    "df['avg_active_days_30d'] = df['avg_active_days_30d'].fillna(0)\n",
    "df['days_since_last_login'] = df['days_since_last_login'].fillna(999)\n",
    "df['inactive_7d_count'] = df['inactive_7d_count'].fillna(0)\n",
    "df['active_courses'] = df['active_courses'].fillna(0)\n",
    "df['completed_courses'] = df['completed_courses'].fillna(0)\n",
    "df['has_downgraded'] = df['has_downgraded'].fillna(0).astype(int)\n",
    "\n",
    "print(f\"Loaded {len(df):,} premium users with activity data\")\n",
    "\n",
    "#To be considered a churned customer, multiple criteria must be met as defined below:\n",
    "df['is_churned'] = (\n",
    "    (\n",
    "        (df['rfm_recency'] > 45) | \n",
    "        (df['segment_label'] == 'Recently Churned')  \n",
    "    ) |\n",
    "    (\n",
    "        (df['has_downgraded'] == 1) & (df['rfm_recency'] > 14) \n",
    "    ) |\n",
    "    (\n",
    "        (df['logins_90d'] == 0) & (df['lessons_completed_90d'] == 0) \n",
    "    )\n",
    ").astype(int)\n",
    "\n",
    "print(\"\\nChurn Distribution:\")\n",
    "churn_counts = df['is_churned'].value_counts()\n",
    "print(f\"  Retained (0):  {churn_counts.get(0, 0):,} ({churn_counts.get(0, 0)/len(df)*100:.1f}%)\")\n",
    "print(f\"  Churned (1):   {churn_counts.get(1, 0):,} ({churn_counts.get(1, 0)/len(df)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nChurn Breakdown by Reason:\")\n",
    "print(f\"  Inactive (>30 days):          {(df['rfm_recency'] > 30).sum():,}\")\n",
    "print(f\"  In churned segments:          {df['segment_label'].isin(['Recently Churned', 'Dormant Premium']).sum():,}\")\n",
    "print(f\"  Downgraded subscription:      {(df['has_downgraded'] == 1).sum():,}\")\n",
    "print(f\"  Very low engagement:          {((df['logins_90d'] < 2) & (df['lessons_completed_90d'] == 0)).sum():,}\")\n",
    "print(f\"  Total churned (with overlap): {df['is_churned'].sum():,}\")\n",
    "\n",
    "print(\"\\nActivity Statistics:\")\n",
    "print(f\"  Avg logins (90d):             {df['logins_90d'].mean():.1f}\")\n",
    "print(f\"  Avg minutes watched (90d):    {df['minutes_watched_90d'].mean():.1f}\")\n",
    "print(f\"  Avg lessons completed (90d):  {df['lessons_completed_90d'].mean():.1f}\")\n",
    "print(f\"  Avg active courses:           {df['active_courses'].mean():.1f}\")\n",
    "\n",
    "print(\"\\nChurn target variable created with activity features\")\n",
    "\n",
    "rfm_df = df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7ad7327-f6fa-4bd8-a485-59feccdcd385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FEATURE ENGINEERING (90-DAY PERIOD)\n",
      "================================================================================\n",
      "Total features available: 42\n"
     ]
    }
   ],
   "source": [
    "#Feature engineering\n",
    "print(\"=\"*80)\n",
    "print(\"FEATURE ENGINEERING (90-DAY PERIOD)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# RFM derived features\n",
    "rfm_df['rfm_score_total'] = rfm_df['rfm_r_score'] + rfm_df['rfm_f_score'] + rfm_df['rfm_m_score']\n",
    "rfm_df['rfm_score_avg'] = rfm_df['rfm_score_total'] / 3\n",
    "\n",
    "# Activity-based features\n",
    "rfm_df['avg_session_duration'] = np.where(\n",
    "    rfm_df['sessions_90d'] > 0,\n",
    "    rfm_df['minutes_watched_90d'] / rfm_df['sessions_90d'],\n",
    "    0\n",
    ")\n",
    "\n",
    "rfm_df['login_frequency'] = rfm_df['logins_90d'] / 90 \n",
    "rfm_df['lesson_completion_rate'] = np.where(\n",
    "    rfm_df['sessions_90d'] > 0,\n",
    "    rfm_df['lessons_completed_90d'] / rfm_df['sessions_90d'],\n",
    "    0\n",
    ")\n",
    "\n",
    "rfm_df['quiz_engagement_rate'] = np.where(\n",
    "    rfm_df['lessons_completed_90d'] > 0,\n",
    "    rfm_df['quizzes_attempted_90d'] / rfm_df['lessons_completed_90d'],\n",
    "    0\n",
    ")\n",
    "\n",
    "rfm_df['course_completion_ratio'] = np.where(\n",
    "    rfm_df['courses_accessed'] > 0,\n",
    "    rfm_df['completed_courses'] / rfm_df['courses_accessed'],\n",
    "    0\n",
    ")\n",
    "\n",
    "# Engagement score (0-100)\n",
    "rfm_df['engagement_score'] = (\n",
    "    (rfm_df['logins_90d'] / rfm_df['logins_90d'].max() * 100) * 0.2 +\n",
    "    (rfm_df['minutes_watched_90d'] / rfm_df['minutes_watched_90d'].max() * 100) * 0.3 +\n",
    "    (rfm_df['lessons_completed_90d'] / rfm_df['lessons_completed_90d'].max() * 100) * 0.3 +\n",
    "    (rfm_df['active_courses'] / rfm_df['active_courses'].max() * 100) * 0.2\n",
    ").fillna(0)\n",
    "\n",
    "# Risk flags \n",
    "rfm_df['high_recency_risk'] = (rfm_df['rfm_recency'] > 45).astype(int) \n",
    "rfm_df['low_activity_risk'] = (rfm_df['logins_90d'] < 5).astype(int)   \n",
    "rfm_df['no_lessons_risk'] = (rfm_df['lessons_completed_90d'] == 0).astype(int)\n",
    "rfm_df['no_active_courses_risk'] = (rfm_df['active_courses'] == 0).astype(int)\n",
    "rfm_df['low_watch_time_risk'] = (rfm_df['minutes_watched_90d'] < 120).astype(int) \n",
    "\n",
    "# Subscription features\n",
    "rfm_df['is_premium_tier'] = rfm_df['subscription_plan_key'].isin([4, 5]).astype(int)\n",
    "rfm_df['is_annual'] = rfm_df['subscription_plan_key'].isin([3, 5]).astype(int)\n",
    "\n",
    "# Interaction features\n",
    "rfm_df['engagement_x_frequency'] = rfm_df['engagement_score'] * rfm_df['rfm_frequency']\n",
    "rfm_df['recency_x_logins'] = rfm_df['rfm_recency'] * rfm_df['logins_90d']\n",
    "\n",
    "print(f\"Total features available: {len(rfm_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e0824f7-ba29-48c1-8d19-347e954bee22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PREPARING TRAINING DATA (90-DAY FEATURES)\n",
      "================================================================================\n",
      "Features prepared:\n",
      "  Shape: (802, 27)\n",
      "  Features: 27\n",
      "  Target: 802 samples\n",
      "\n",
      "Feature Categories:\n",
      "  RFM raw features:      3 (recency, frequency, monetary)\n",
      "  Activity features:    10 (90-day window)\n",
      "  Derived features:      6\n",
      "  Risk flags:            5\n",
      "  Subscription:          3\n",
      "  Total:                27\n",
      "\n",
      "Train/Test Split:\n",
      "  Training set:   641 samples (79.9%)\n",
      "  Test set:       161 samples (20.1%)\n",
      "\n",
      "  Train - Churned: 254 (39.6%)\n",
      "  Test - Churned:  64 (39.8%)\n"
     ]
    }
   ],
   "source": [
    "#Prepare features for training\n",
    "print(\"=\"*80)\n",
    "print(\"PREPARING TRAINING DATA (90-DAY FEATURES)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Select features for model \n",
    "feature_columns = [\n",
    "    'rfm_recency',\n",
    "    'rfm_frequency',\n",
    "    'rfm_monetary',\n",
    "    \n",
    "    # Activity features\n",
    "    'logins_90d',\n",
    "    'sessions_90d',\n",
    "    'minutes_watched_90d',\n",
    "    'lessons_completed_90d',\n",
    "    'quizzes_attempted_90d',\n",
    "    'courses_accessed',\n",
    "    'avg_active_days_30d',\n",
    "    'days_since_last_login',\n",
    "    'active_courses',\n",
    "    'completed_courses',\n",
    "    \n",
    "    # Derived activity features\n",
    "    'avg_session_duration',\n",
    "    'login_frequency',\n",
    "    'lesson_completion_rate',\n",
    "    'quiz_engagement_rate',\n",
    "    'course_completion_ratio',\n",
    "    'engagement_score',\n",
    "    \n",
    "    # Risk flags\n",
    "    'high_recency_risk',\n",
    "    'low_activity_risk',\n",
    "    'no_lessons_risk',\n",
    "    'no_active_courses_risk',\n",
    "    'low_watch_time_risk',\n",
    "    \n",
    "    # Subscription features\n",
    "    'is_premium_tier',\n",
    "    'is_annual',\n",
    "    'has_downgraded'\n",
    "]\n",
    "\n",
    "X = rfm_df[feature_columns].copy()\n",
    "y = rfm_df['is_churned'].copy()\n",
    "\n",
    "X = X.replace([np.inf, -np.inf], 0)\n",
    "X = X.fillna(0)\n",
    "\n",
    "print(f\"Features prepared:\")\n",
    "print(f\"  Shape: {X.shape}\")\n",
    "print(f\"  Features: {len(feature_columns)}\")\n",
    "print(f\"  Target: {len(y)} samples\")\n",
    "print(f\"\\nFeature Categories:\")\n",
    "print(f\"  RFM raw features:      3 (recency, frequency, monetary)\")\n",
    "print(f\"  Activity features:    10 (90-day window)\")\n",
    "print(f\"  Derived features:      6\")\n",
    "print(f\"  Risk flags:            5\")\n",
    "print(f\"  Subscription:          3\")\n",
    "print(f\"  Total:                {len(feature_columns)}\")\n",
    "\n",
    "# Making the split into train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain/Test Split:\")\n",
    "print(f\"  Training set:   {len(X_train):,} samples ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"  Test set:       {len(X_test):,} samples ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "print(f\"\\n  Train - Churned: {y_train.sum():,} ({y_train.sum()/len(y_train)*100:.1f}%)\")\n",
    "print(f\"  Test - Churned:  {y_test.sum():,} ({y_test.sum()/len(y_test)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2eee5388-99ff-42aa-8dbb-c31c22d6f1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TRAINING CHURN PREDICTION MODEL\n",
      "================================================================================\n",
      "Training Random Forest Classifier...\n",
      "  n_estimators: 100\n",
      "  max_depth: 10\n",
      "  class_weight: balanced\n",
      "\n",
      "Model training complete!\n",
      "Predictions generated\n"
     ]
    }
   ],
   "source": [
    "#We will be using Random Forest Classifier for predictions\n",
    "print(\"=\"*80)\n",
    "print(\"TRAINING CHURN PREDICTION MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_split=20,\n",
    "    min_samples_leaf=10,\n",
    "    random_state=42,\n",
    "    class_weight='balanced', \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Training Random Forest Classifier...\")\n",
    "print(f\"  n_estimators: 100\")\n",
    "print(f\"  max_depth: 10\")\n",
    "print(f\"  class_weight: balanced\")\n",
    "print()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Model training complete!\")\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "y_train_proba = model.predict_proba(X_train)[:, 1]\n",
    "y_test_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Predictions generated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a66bf9bb-1fb0-477b-8264-e568007343c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MODEL PERFORMANCE EVALUATION\n",
      "================================================================================\n",
      "\n",
      "TRAINING SET PERFORMANCE:\n",
      "  Accuracy:   93.6%\n",
      "  Precision:  94.9%\n",
      "  Recall:     88.6%\n",
      "  F1-Score:   91.6%\n",
      "  AUC-ROC:    0.983\n",
      "\n",
      "TEST SET PERFORMANCE:\n",
      "  Accuracy:   83.2%\n",
      "  Precision:  81.4%\n",
      "  Recall:     75.0%\n",
      "  F1-Score:   78.0%\n",
      "  AUC-ROC:    0.936\n",
      "\n",
      "CONFUSION MATRIX (Test Set):\n",
      "  True Negatives:  86 (Correctly predicted retained)\n",
      "  False Positives: 11 (Predicted churned, actually retained)\n",
      "  False Negatives: 16 (Predicted retained, actually churned)\n",
      "  True Positives:  48 (Correctly predicted churned)\n",
      "\n",
      "DETAILED CLASSIFICATION REPORT:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Retained       0.84      0.89      0.86        97\n",
      "     Churned       0.81      0.75      0.78        64\n",
      "\n",
      "    accuracy                           0.83       161\n",
      "   macro avg       0.83      0.82      0.82       161\n",
      "weighted avg       0.83      0.83      0.83       161\n",
      "\n",
      "Saved model metrics (ID: 1)\n",
      "\n",
      "Model evaluation complete!\n"
     ]
    }
   ],
   "source": [
    "#Model performance evaluation\n",
    "print(\"=\"*80)\n",
    "print(\"MODEL PERFORMANCE EVALUATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "train_precision = precision_score(y_train, y_train_pred)\n",
    "test_precision = precision_score(y_test, y_test_pred)\n",
    "\n",
    "train_recall = recall_score(y_train, y_train_pred)\n",
    "test_recall = recall_score(y_test, y_test_pred)\n",
    "\n",
    "train_f1 = f1_score(y_train, y_train_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "train_auc = roc_auc_score(y_train, y_train_proba)\n",
    "test_auc = roc_auc_score(y_test, y_test_proba)\n",
    "\n",
    "print(\"\\nTRAINING SET PERFORMANCE:\")\n",
    "print(f\"  Accuracy:   {train_accuracy*100:.1f}%\")\n",
    "print(f\"  Precision:  {train_precision*100:.1f}%\")\n",
    "print(f\"  Recall:     {train_recall*100:.1f}%\")\n",
    "print(f\"  F1-Score:   {train_f1*100:.1f}%\")\n",
    "print(f\"  AUC-ROC:    {train_auc:.3f}\")\n",
    "\n",
    "print(\"\\nTEST SET PERFORMANCE:\")\n",
    "print(f\"  Accuracy:   {test_accuracy*100:.1f}%\")\n",
    "print(f\"  Precision:  {test_precision*100:.1f}%\")\n",
    "print(f\"  Recall:     {test_recall*100:.1f}%\")\n",
    "print(f\"  F1-Score:   {test_f1*100:.1f}%\")\n",
    "print(f\"  AUC-ROC:    {test_auc:.3f}\")\n",
    "\n",
    "print(\"\\nCONFUSION MATRIX (Test Set):\")\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "print(f\"  True Negatives:  {cm[0,0]:,} (Correctly predicted retained)\")\n",
    "print(f\"  False Positives: {cm[0,1]:,} (Predicted churned, actually retained)\")\n",
    "print(f\"  False Negatives: {cm[1,0]:,} (Predicted retained, actually churned)\")\n",
    "print(f\"  True Positives:  {cm[1,1]:,} (Correctly predicted churned)\")\n",
    "\n",
    "print(\"\\nDETAILED CLASSIFICATION REPORT:\")\n",
    "print(classification_report(y_test, y_test_pred, target_names=['Retained', 'Churned']))\n",
    "\n",
    "# Store metrics to database\n",
    "with SessionLocal() as session:\n",
    "    metrics = ModelPerformanceMetrics(\n",
    "        snapshot_date_key=snapshot_date_key,\n",
    "        model_type='churn_prediction',\n",
    "        model_version='v1.0',\n",
    "        accuracy=round(test_accuracy, 4),\n",
    "        precision=round(test_precision, 4),\n",
    "        recall=round(test_recall, 4),\n",
    "        f1_score=round(test_f1, 4),\n",
    "        auc_roc=round(test_auc, 4),\n",
    "        train_samples=len(X_train),\n",
    "        test_samples=len(X_test),\n",
    "        true_negatives=int(cm[0, 0]),\n",
    "        false_positives=int(cm[0, 1]),\n",
    "        false_negatives=int(cm[1, 0]),\n",
    "        true_positives=int(cm[1, 1])\n",
    "    )\n",
    "    session.add(metrics)\n",
    "    session.commit()\n",
    "    print(f\"Saved model metrics (ID: {metrics.model_performance_id})\")\n",
    "\n",
    "print(\"\\nModel evaluation complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00f34d0d-8c58-445b-85c1-fdd643801847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FEATURE IMPORTANCE ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "TOP 15 MOST IMPORTANT FEATURES:\n",
      "          feature_name  importance_score  importance_rank\n",
      "           rfm_recency         38.379097                1\n",
      "         rfm_frequency         16.904763                2\n",
      "          rfm_monetary          9.930012                3\n",
      "     high_recency_risk          7.223636                4\n",
      "        has_downgraded          3.742220                5\n",
      "   minutes_watched_90d          2.767173                6\n",
      "  quiz_engagement_rate          2.420689                7\n",
      " quizzes_attempted_90d          2.190667                8\n",
      "      engagement_score          2.058060                9\n",
      "lesson_completion_rate          2.051757               10\n",
      "  avg_session_duration          1.989870               11\n",
      "   avg_active_days_30d          1.856666               12\n",
      " lessons_completed_90d          1.703641               13\n",
      "            logins_90d          1.469900               14\n",
      "          sessions_90d          1.465102               15\n",
      "\n",
      "Feature importance saved to database (27 features)\n"
     ]
    }
   ],
   "source": [
    "# Analyzing and saving feature importance\n",
    "print(\"=\"*80)\n",
    "print(\"FEATURE IMPORTANCE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature_name': feature_columns,\n",
    "    'importance_score': model.feature_importances_\n",
    "}).sort_values('importance_score', ascending=False)\n",
    "\n",
    "feature_importance['importance_score'] = (\n",
    "    feature_importance['importance_score'] / feature_importance['importance_score'].sum() * 100\n",
    ")\n",
    "\n",
    "feature_importance['importance_rank'] = range(1, len(feature_importance) + 1)\n",
    "\n",
    "print(\"\\nTOP 15 MOST IMPORTANT FEATURES:\")\n",
    "print(feature_importance.head(15).to_string(index=False))\n",
    "\n",
    "feature_importance_db = feature_importance.copy()\n",
    "feature_importance_db['snapshot_date_key'] = snapshot_date_key\n",
    "feature_importance_db['model_type'] = 'churn_prediction'\n",
    "feature_importance_db['model_version'] = 'v1.0'\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    feature_importance_db.to_sql(\n",
    "        'feature_importance',\n",
    "        con=conn,\n",
    "        if_exists='append',\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "print(f\"\\nFeature importance saved to database ({len(feature_importance_db)} features)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc1e6e2e-f58c-4d26-936a-0badfb3d43f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PREDICTING CHURN FOR ALL USERS\n",
      "================================================================================\n",
      "Churn predictions generated for 802 users\n",
      "\n",
      "Churn Risk Distribution:\n",
      "  Minimal Risk        : 246 (30.7%)\n",
      "  High Risk           : 198 (24.7%)\n",
      "  Low Risk            : 194 (24.2%)\n",
      "  Medium Risk         : 164 (20.4%)\n",
      "\n",
      "Churn Probability Statistics:\n",
      "  Mean:    0.438\n",
      "  Median:  0.309\n",
      "  Min:     0.047\n",
      "  Max:     0.989\n"
     ]
    }
   ],
   "source": [
    "#Predicting churn probability for all users\n",
    "print(\"=\"*80)\n",
    "print(\"PREDICTING CHURN FOR ALL USERS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "X_full = rfm_df[feature_columns].copy()\n",
    "X_full = X_full.replace([np.inf, -np.inf], 0).fillna(0)\n",
    "\n",
    "churn_predictions = model.predict_proba(X_full)[:, 1]\n",
    "rfm_df['churn_probability_predicted'] = churn_predictions\n",
    "\n",
    "def classify_churn_risk(prob):\n",
    "    if prob >= 0.7:\n",
    "        return 'High Risk'\n",
    "    elif prob >= 0.4:\n",
    "        return 'Medium Risk'\n",
    "    elif prob >= 0.2:\n",
    "        return 'Low Risk'\n",
    "    else:\n",
    "        return 'Minimal Risk'\n",
    "\n",
    "rfm_df['churn_risk_band_predicted'] = rfm_df['churn_probability_predicted'].apply(classify_churn_risk)\n",
    "\n",
    "print(f\"Churn predictions generated for {len(rfm_df):,} users\")\n",
    "\n",
    "print(\"\\nChurn Risk Distribution:\")\n",
    "risk_dist = rfm_df['churn_risk_band_predicted'].value_counts()\n",
    "for risk, count in risk_dist.items():\n",
    "    pct = count / len(rfm_df) * 100\n",
    "    print(f\"  {risk:20s}: {count:,} ({pct:.1f}%)\")\n",
    "\n",
    "print(\"\\nChurn Probability Statistics:\")\n",
    "print(f\"  Mean:    {rfm_df['churn_probability_predicted'].mean():.3f}\")\n",
    "print(f\"  Median:  {rfm_df['churn_probability_predicted'].median():.3f}\")\n",
    "print(f\"  Min:     {rfm_df['churn_probability_predicted'].min():.3f}\")\n",
    "print(f\"  Max:     {rfm_df['churn_probability_predicted'].max():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52a8038a-4865-412d-9425-e069c68a9dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "UPDATING DATABASE WITH CHURN PREDICTIONS\n",
      "================================================================================\n",
      "Updating 802 user records...\n",
      "Updated 500 records...\n",
      "\n",
      "Updated 802 records in fact_user_analytics_snapshot\n",
      "\n",
      "Verification:\n",
      "  Total records:         1,000\n",
      "  With churn_probability: 802\n",
      "  With churn_risk_band:  802\n",
      "\n",
      "Database update complete!\n"
     ]
    }
   ],
   "source": [
    "#Updating fact_user_analytics_snapshot with churn predictions\n",
    "print(\"=\"*80)\n",
    "print(\"UPDATING DATABASE WITH CHURN PREDICTIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "update_df = rfm_df[['user_key', 'churn_probability_predicted', 'churn_risk_band_predicted']].copy()\n",
    "\n",
    "print(f\"Updating {len(update_df):,} user records...\")\n",
    "\n",
    "updated_count = 0\n",
    "with engine.begin() as conn:\n",
    "    for idx, row in update_df.iterrows():\n",
    "        conn.execute(text(\"\"\"\n",
    "            UPDATE fact_user_analytics_snapshot\n",
    "            SET churn_probability = :churn_prob,\n",
    "                churn_risk_band = :risk_band\n",
    "            WHERE user_key = :user_key\n",
    "              AND snapshot_date_key = :snap_date\n",
    "        \"\"\"), {\n",
    "            'churn_prob': float(row['churn_probability_predicted']),\n",
    "            'risk_band': row['churn_risk_band_predicted'],\n",
    "            'user_key': int(row['user_key']),\n",
    "            'snap_date': snapshot_date_key\n",
    "        })\n",
    "        updated_count += 1\n",
    "        \n",
    "        if updated_count % 500 == 0:\n",
    "            print(f\"Updated {updated_count:,} records...\")\n",
    "\n",
    "print(f\"\\nUpdated {updated_count:,} records in fact_user_analytics_snapshot\")\n",
    "\n",
    "# Verifying to see if updates took place\n",
    "with engine.connect() as conn:\n",
    "    verify_query = text(\"\"\"\n",
    "        SELECT \n",
    "            COUNT(*) as total,\n",
    "            COUNT(churn_probability) as has_churn_prob,\n",
    "            COUNT(churn_risk_band) as has_risk_band\n",
    "        FROM fact_user_analytics_snapshot\n",
    "        WHERE snapshot_date_key = :snap_date\n",
    "    \"\"\")\n",
    "    \n",
    "    verify_df = pd.read_sql(verify_query, conn, params={'snap_date': snapshot_date_key})\n",
    "    \n",
    "    print(\"\\nVerification:\")\n",
    "    print(f\"  Total records:         {verify_df['total'].iloc[0]:,}\")\n",
    "    print(f\"  With churn_probability: {verify_df['has_churn_prob'].iloc[0]:,}\")\n",
    "    print(f\"  With churn_risk_band:  {verify_df['has_risk_band'].iloc[0]:,}\")\n",
    "\n",
    "print(\"\\nDatabase update complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc9ca87c-1d84-4b17-a2a1-022629ea81e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ANALYZING CHURN REASONS\n",
      "================================================================================\n",
      "Analyzing 362 at-risk users...\n",
      "\n",
      "CHURN REASONS BREAKDOWN:\n",
      "reason_category  reason_count  avg_churn_probability  reason_pct             reason_display_name severity_level  snapshot_date_key\n",
      "Downgraded Plan           156               0.652966        43.1          Subscription Downgrade         Medium           20251128\n",
      "     Inactivity           155               0.868262        42.8 Prolonged Inactivity (30+ days)           High           20251128\n",
      "          Other            51               0.512238        14.1                   Other Factors         Medium           20251128\n",
      "\n",
      "Churn reasons saved to database (3 categories)\n"
     ]
    }
   ],
   "source": [
    "#Analyzing churn reasons and save to database\n",
    "print(\"=\"*80)\n",
    "print(\"ANALYZING CHURN REASONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "#Identifying at-risk users (High + Medium risk)\n",
    "at_risk_users = rfm_df[rfm_df['churn_risk_band_predicted'].isin(['High Risk', 'Medium Risk'])].copy()\n",
    "\n",
    "print(f\"Analyzing {len(at_risk_users):,} at-risk users...\")\n",
    "\n",
    "def classify_churn_reason(row):\n",
    "    reasons = []\n",
    "    \n",
    "    if row['rfm_recency'] > 30:\n",
    "        reasons.append('Inactivity')\n",
    "    if row['logins_90d'] < 3:\n",
    "        reasons.append('Low Engagement')\n",
    "    if row['lessons_completed_90d'] == 0:\n",
    "        reasons.append('Course Dropped')\n",
    "    if row['active_courses'] == 0:\n",
    "        reasons.append('No Active Courses')\n",
    "    if row['minutes_watched_90d'] < 60:\n",
    "        reasons.append('Low Watch Time')\n",
    "    if row['has_downgraded'] == 1:\n",
    "        reasons.append('Downgraded Plan')\n",
    "    if row['quiz_engagement_rate'] == 0 and row['lessons_completed_90d'] > 0:\n",
    "        reasons.append('Low Quiz Engagement')\n",
    "        \n",
    "    return reasons[0] if reasons else 'Other'\n",
    "\n",
    "at_risk_users['primary_churn_reason'] = at_risk_users.apply(classify_churn_reason, axis=1)\n",
    "\n",
    "churn_reasons_agg = at_risk_users.groupby('primary_churn_reason').agg({\n",
    "    'user_key': 'count',\n",
    "    'churn_probability_predicted': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "churn_reasons_agg.columns = ['reason_category', 'reason_count', 'avg_churn_probability']\n",
    "churn_reasons_agg['reason_pct'] = (churn_reasons_agg['reason_count'] / len(at_risk_users) * 100).round(1)\n",
    "\n",
    "reason_display_map = {\n",
    "    'Inactivity': 'Prolonged Inactivity (30+ days)',\n",
    "    'Low Engagement': 'Low Platform Engagement',\n",
    "    'Course Dropped': 'No Lessons Completed',\n",
    "    'No Active Courses': 'No Active Courses',\n",
    "    'Low Watch Time': 'Minimal Watch Time',\n",
    "    'Downgraded Plan': 'Subscription Downgrade',\n",
    "    'Low Quiz Engagement': 'Low Quiz Participation',\n",
    "    'Other': 'Other Factors'\n",
    "}\n",
    "\n",
    "churn_reasons_agg['reason_display_name'] = churn_reasons_agg['reason_category'].map(reason_display_map)\n",
    "\n",
    "def assign_severity(avg_prob):\n",
    "    if avg_prob >= 0.7:\n",
    "        return 'High'\n",
    "    elif avg_prob >= 0.4:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'Low'\n",
    "\n",
    "churn_reasons_agg['severity_level'] = churn_reasons_agg['avg_churn_probability'].apply(assign_severity)\n",
    "\n",
    "churn_reasons_agg['snapshot_date_key'] = snapshot_date_key\n",
    "\n",
    "print(\"\\nCHURN REASONS BREAKDOWN:\")\n",
    "print(churn_reasons_agg.sort_values('reason_count', ascending=False).to_string(index=False))\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    churn_reasons_agg.to_sql(\n",
    "        'churn_reasons',\n",
    "        con=conn,\n",
    "        if_exists='append',\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "print(f\"\\nChurn reasons saved to database ({len(churn_reasons_agg)} categories)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f517608-d5c9-4d36-9021-d9135e21819d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
